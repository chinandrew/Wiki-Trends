{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using LightGraphs\n",
    "using DataFrames\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "inverse logit function\n",
    "\"\"\"\n",
    "invLogit(x) = 1./(1.+e.^-x)   \n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "given graph and probability, adds a node which must have >0\n",
    "connections by flipping biased coin for each existing node\n",
    "\"\"\"\n",
    "function addNode2(graph, p)\n",
    "    add_vertex!(graph)\n",
    "    x = nv(graph)\n",
    "    degree = 0\n",
    "    while degree ==0\n",
    "        flips = rand(x-1)\n",
    "        for i = 1:x-1\n",
    "            if p[i]>flips[i]\n",
    "                add_edge!(graph,i,x)\n",
    "                degree +=1 \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return graph\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "given graph, b vector, and a_0, adds a new node as specifiec by the model\n",
    "\"\"\"\n",
    "function addPrefNode(g,b,a_0 = -7)\n",
    "    n = nv(g)\n",
    "    L::SparseMatrixCSC{Int64,Int64} = laplacian_matrix(g)\n",
    "    a::Array{Float64,1} = lufact(L) \\ (b - mean(b))\n",
    "    p::Array{Float64,1} = invLogit(a+a_0)\n",
    "    addNode2(g,p)\n",
    "    push!(b,0)\n",
    "    return g\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "given graph and number of new edges desired, randomly adds edges between existing nodes\n",
    "\"\"\"\n",
    "function randEdgeGen(graph, newedges)\n",
    "    for i in 1:newedges\n",
    "        z = newedges\n",
    "        x = collect(1:nv(graph))\n",
    "        edge1 = rand(x)\n",
    "        deleteat!(x, edge1)\n",
    "        edge2 = rand(x)\n",
    "        add_edge!(graph,edge1,edge2)\n",
    "    end\n",
    "    return graph\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition invLogit(Any) in module Main at In[1]:10 overwritten at In[2]:3.\n"
     ]
    }
   ],
   "source": [
    "#outputs same as input\n",
    "\n",
    "invLogit(x) = 1./(1.+e.^-x)   \n",
    "\n",
    "\n",
    "\n",
    "#outputs same as input\n",
    "soft(c,lambda) = sign(c).*max(abs(c)-lambda/2,0)\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "function gradient(a,a_0,u,L,rho,b,y)\n",
    "    grad = -1.*(y-invLogit(a+a_0))+L*u + rho*L*(L*a-b)\n",
    "    return grad\n",
    "end;\n",
    "\n",
    "function hessian(a,a_0,rho,L)\n",
    "    hess = Diagonal(vec((invLogit(a+a_0).*(1-invLogit(a+a_0)))))+rho*L^2\n",
    "    return hess\n",
    "end;\n",
    "\n",
    "\n",
    "\n",
    "function newton(y,a_0,L,rho,b,u)\n",
    "    a= zeros(length(y))\n",
    "    a_old = a\n",
    "    iters = 0\n",
    "    diff = 1.0\n",
    "    while(diff >STOP_DIFF && iters< MAX_ITER )\n",
    "        grad = gradient(a_old,a_0,u,L,rho,b,y)\n",
    "        hess = hessian(a_old,a_0, rho,L)\n",
    "        a = a_old - inv(hess)*grad\n",
    "        diff = norm(a-a_old)\n",
    "        a_old = a\n",
    "        iters = iters+1\n",
    "    end\n",
    "    if(iters == MAX_ITER)\n",
    "        print(\"max iter reached\")\n",
    "    end\n",
    "    return a\n",
    "end\n",
    ";\n",
    "\n",
    "\n",
    "\n",
    "function ADMM(A,L, rho, lambda, a_0)\n",
    "    t_0 = length(A[1])\n",
    "    t = length(A[size(A)[1]])\n",
    "\tnew = size(A)[1] \n",
    "    a = Array{Float64,1}[]\n",
    "    u = Array{Float64,1}[]\n",
    "    for i in t_0:t\n",
    "        push!(a,zeros(i)+0.0)\n",
    "        push!(u,zeros(i)+0.0)\n",
    "    end\n",
    "\tb = zeros(t_0)\n",
    "\titers = 0\n",
    "\tdiff = 1.0\n",
    "\tb_old = b\n",
    "\twhile(diff >STOP_DIFF && iters< MAX_ITER )\n",
    "\t\tfor i in 1:new\n",
    "            a[i] = newton(A[i],a_0,L[i],rho,vcat(b,zeros(i-1)),u[i])\n",
    "        end\n",
    "        c = zeros(t)\n",
    "        for i in 1:new \n",
    "        \tc[1:(t_0 +i-1)] = c[1:(t_0 +i-1)]+ (u[i]+rho*(L[i]*a[i]))/(rho*new)\n",
    "        end\n",
    "        b = soft(c[1:t_0],2*lambda/rho)\n",
    "        #u update\n",
    "        for i in 1:new\n",
    "            u[i] = u[i]+ rho*(L[i]*a[i]-vcat(b,zeros(i-1)))\n",
    "        end\n",
    "        diff  = norm(b-b_old)\n",
    "        b_old = b\n",
    "        println(diff)\n",
    "    end\n",
    "    return(b)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using arXiv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const MAX_ITER = 1000\n",
    "const STOP_DIFF = 0.001;\n",
    "\n",
    "rho = 1\n",
    "lambda = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using LightGraphs\n",
    "using DataFrames\n",
    "\n",
    "\n",
    "data = readtable(\"~/arXiv/training.csv\")  #change directory\n",
    "\n",
    "t = maximum([maximum(data[:,4]),maximum(data[:,5])])\n",
    "g = BinaryTree(0)\n",
    "for i in 1:t\n",
    "\tadd_vertex!(g)\n",
    "end\n",
    "for i in 1:size(data,1)\n",
    "\tadd_edge!(g,data[i,4],data[i,5])\n",
    "end\n",
    "At = adjacency_matrix(g)\n",
    "\n",
    "\n",
    "A = Array{Int64,1}[]\n",
    "L =  SparseMatrixCSC{Int64,Int64}[]\n",
    "Adj =  SparseMatrixCSC{Int64,Int64}[]\n",
    "\n",
    "new = 1\n",
    "for i in reverse(1:new)\n",
    "    n = size(At)[1]\n",
    "    push!(A,full(At[n-i+1,1:n-i]))\n",
    "    push!(Adj, At[1:n-i,1:n-i])\n",
    "end\n",
    "\n",
    "for adj in Adj\n",
    "    push!(L,spdiagm(vec(sum(Adj[1],1))).-Adj[1])\n",
    "end\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original, not enough variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels = 10     #number of levels in binary tree\n",
    "g = BinaryTree(levels)\n",
    "n = nv(g)\n",
    "b = (rand(n) .< 8 / n)*5. \n",
    "genb = copy(b)  # save for later\n",
    "g = randEdgeGen(g,10000)\n",
    "A = Array{Int64,1}[]\n",
    "L =  SparseMatrixCSC{Int64,Int64}[]\n",
    "numnewnodes = 5\n",
    "a_0 = -4\n",
    "# creates matrix A and L where A[i] is the connections for ith node and L[i] is the laplacian of the i-1st time step \n",
    "for i in 1:numnewnodes \n",
    "    push!(L, laplacian_matrix(g))\n",
    "    g = addPrefNode(g,b, a_0)\n",
    "    connects = zeros(2^levels-2+i)  #-1 for -1 1 coding\n",
    "    connects[neighbors(g,nv(g))] = 1\n",
    "    push!(A,connects)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more variation needs work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "const MAX_ITER = 1000\n",
    "const STOP_DIFF = 0.001;\n",
    "\n",
    "rho = 1\n",
    "lambda = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels = 10     #number of levels in binary tree\n",
    "g = BinaryTree(levels)\n",
    "n = nv(g)\n",
    "\n",
    "#dist = Gamma(2,2)\n",
    "#b = 50.*rand(dist,n)\n",
    "b = vec(readdlm(\"bvec.dat\"))\n",
    "\n",
    "genb = copy(b)  # save for later\n",
    "g = randEdgeGen(g,10000)\n",
    "A = Array{Int64,1}[]\n",
    "L =  SparseMatrixCSC{Int64,Int64}[]\n",
    "a_0 = 62\n",
    "numnewnodes = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creates matrix A and L where A[i] is the connections for ith node and L[i] is the laplacian of the i-1st time step \n",
    "for i in 1:numnewnodes \n",
    "    push!(L, laplacian_matrix(g))\n",
    "    g = addPrefNode(g,b,a_0 )\n",
    "    connects = zeros(2^levels-2+i)  #-1 for -1 1 coding\n",
    "    connects[neighbors(g,nv(g))] = 1\n",
    "    push!(A,connects)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    t_0 = length(A[1])\n",
    "    t = length(A[size(A)[1]])\n",
    "\tnew = size(A)[1] \n",
    "    a = Array{Float64,1}[]\n",
    "    u = Array{Float64,1}[]\n",
    "    for i in t_0:t\n",
    "        push!(a,zeros(i)+0.0)\n",
    "        push!(u,zeros(i)+0.0)\n",
    "    end\n",
    "\tb = zeros(t_0)\n",
    "\titers = 0\n",
    "\tdiff = 1.0\n",
    "\tb_old = b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]0.0\n",
      "[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]0.0\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      " in #sortSparseMatrixCSC!#53(::Symbol, ::Function, ::SparseMatrixCSC{Int64,Int64}) at ./sparse/sparsematrix.jl:3657",
      " in (::Base.SparseArrays.#kw##sortSparseMatrixCSC!)(::Array{Any,1}, ::Base.SparseArrays.#sortSparseMatrixCSC!, ::SparseMatrixCSC{Int64,Int64}) at ./<missing>:0",
      " in #spmatmul#62(::Symbol, ::Function, ::SparseMatrixCSC{Int64,Int64}, ::SparseMatrixCSC{Int64,Int64}) at ./sparse/linalg.jl:192",
      " in power_by_squaring(::SparseMatrixCSC{Int64,Int64}, ::Int64) at ./intfuncs.jl:116",
      " in hessian(::Array{Float64,1}, ::Int64, ::Int64, ::SparseMatrixCSC{Int64,Int64}) at ./In[2]:19",
      " in newton(::Array{Int64,1}, ::Int64, ::SparseMatrixCSC{Int64,Int64}, ::Int64, ::Array{Float64,1}, ::Array{Float64,1}) at ./In[2]:32",
      " in macro expansion; at ./In[20]:3 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "for k in 1:100\n",
    "        for i in 1:new\n",
    "            a[i] = newton(A[i],a_0,L[i],rho,vcat(b,zeros(i-1)),u[i])\n",
    "        end\n",
    "        c = zeros(t)\n",
    "        for i in 1:new \n",
    "        \tc[1:(t_0 +i-1)] = c[1:(t_0 +i-1)]+ (u[i]+rho*(L[i]*a[i]))/(rho*new)\n",
    "        end\n",
    "    print(c)\n",
    "        b = soft(c[1:t_0],2*lambda/rho)\n",
    "        #u update\n",
    "        for i in 1:new\n",
    "            u[i] = u[i]+ rho*(L[i]*a[i]-vcat(b,zeros(i-1)))\n",
    "        end\n",
    "        diff  = norm(b-b_old)\n",
    "        b_old = b\n",
    "        println(diff)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: c not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: c not defined",
      ""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
