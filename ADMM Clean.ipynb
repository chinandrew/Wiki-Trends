{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using LightGraphs\n",
    "using DataFrames\n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "inverse logit function\n",
    "\"\"\"\n",
    "invLogit(x) = 1./(1.+e.^-x)   \n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "given graph and probability, adds a node which must have >0\n",
    "connections by flipping biased coin for each existing node\n",
    "\"\"\"\n",
    "function addNode(graph, p)\n",
    "    add_vertex!(graph)\n",
    "    x = nv(graph)\n",
    "    degree = 0\n",
    "    while degree ==0\n",
    "        flips = rand(x-1)\n",
    "        for i = 1:x-1\n",
    "            if p[i]>flips[i]\n",
    "                add_edge!(graph,i,x)\n",
    "                degree +=1 \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return graph\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "given graph, b vector, and a_0, adds a new node as specifiec by the model\n",
    "\"\"\"\n",
    "function addPrefNode(g,b,a_0 = -7)\n",
    "    n = nv(g)\n",
    "    L::SparseMatrixCSC{Int64,Int64} = laplacian_matrix(g)\n",
    "    a::Array{Float64,1} = lufact(L) \\ (b - mean(b))\n",
    "    p::Array{Float64,1} = invLogit(a+a_0)\n",
    "    addNode(g,p)\n",
    "    push!(b,0)\n",
    "    return g\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "given graph and number of new edges desired, randomly adds edges between existing nodes\n",
    "\"\"\"\n",
    "function randEdgeGen(graph, newedges)\n",
    "    for i in 1:newedges\n",
    "        z = newedges\n",
    "        x = collect(1:nv(graph))\n",
    "        edge1 = rand(x)\n",
    "        deleteat!(x, edge1)\n",
    "        edge2 = rand(x)\n",
    "        add_edge!(graph,edge1,edge2)\n",
    "    end\n",
    "    return graph\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft threshold, gradient, and hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#outputs same as input\n",
    "soft(c,lambda) = sign(c).*max(abs(c)-lambda/2,0)\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "function gradient(a,a_0,u,L,rho,b,y)\n",
    "    grad = -1.*(y-invLogit(a+a_0))+L*u + rho*L*(L*a-b)\n",
    "    return grad\n",
    "end;\n",
    "\n",
    "function hessian(a,a_0,rho,L)\n",
    "    hess = Diagonal(vec((invLogit(a+a_0).*(1-invLogit(a+a_0)))))+rho*L^2\n",
    "    return hess\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton Raphson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function newton(y,a_0,L,rho,b,u)\n",
    "    a= zeros(length(y))\n",
    "    a_old = a\n",
    "    iters = 0\n",
    "    diff = 1.0\n",
    "    while(diff >STOP_DIFF && iters< MAX_ITER )\n",
    "        grad = gradient(a_old,a_0,u,L,rho,b,y)\n",
    "        hess = hessian(a_old,a_0, rho,L)\n",
    "        a = a_old - inv(hess)*grad\n",
    "        diff = norm(a-a_old)\n",
    "        a_old = a\n",
    "        iters = iters+1\n",
    "    end\n",
    "    if(iters == MAX_ITER)\n",
    "        println(\"max iter reached\")\n",
    "    end\n",
    "    return a\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function grad_descent(y,a_0,L,rho,b,u,step = 0.0005)\n",
    "    a= zeros(length(y))\n",
    "    a_old = a\n",
    "    iters = 0\n",
    "    diff = 1.0\n",
    "    while(diff >STOP_DIFF && iters< MAX_ITER )\n",
    "        grad = gradient(a_old,a_0,u,L,rho,b,y)\n",
    "        a = a_old - grad*step\n",
    "        diff = norm(a.-a_old)\n",
    "        a_old = a\n",
    "        iters = iters+1\n",
    "    end\n",
    "#    if(iters == MAX_ITER)\n",
    "#        println(\"max iter reached\")\n",
    "#   end\n",
    "    return a\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton Raphson ADMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function ADMM(A,L, rho, lambda, a_0)\n",
    "    t_0 = length(A[1])\n",
    "    t = length(A[size(A)[1]])\n",
    "\tnew = size(A)[1] \n",
    "    a = Array{Float64,1}[]\n",
    "    u = Array{Float64,1}[]\n",
    "    for i in t_0:t\n",
    "        push!(a,zeros(i)+0.0)\n",
    "        push!(u,zeros(i)+0.0)\n",
    "    end\n",
    "\tb = zeros(t_0)\n",
    "\titers = 0\n",
    "\tdiff = 1.0\n",
    "\tb_old = b\n",
    "\twhile(diff >STOP_DIFF && iters< MAX_ITER )\n",
    "\t\tfor i in 1:new\n",
    "            a[i] = newton(A[i],a_0,L[i],rho,vcat(b,zeros(i-1)),u[i])\n",
    "        end\n",
    "        c = zeros(t)\n",
    "        for i in 1:new \n",
    "        \tc[1:(t_0 +i-1)] = c[1:(t_0 +i-1)]+ (u[i]+rho*(L[i]*a[i]))/(rho*new)\n",
    "        end\n",
    "        b = soft(c[1:t_0],2*lambda/rho)\n",
    "        #u update\n",
    "        for i in 1:new\n",
    "            u[i] = u[i]+ rho*(L[i]*a[i]-vcat(b,zeros(i-1)))\n",
    "        end\n",
    "        diff  = norm(b-b_old)\n",
    "        b_old = b\n",
    "        println(diff)\n",
    "    end\n",
    "    return(b)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent ADMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function ADMM2(A,L, rho, lambda, a_0)\n",
    "    t_0 = length(A[1])\n",
    "    t = length(A[size(A)[1]])\n",
    "\tnew = size(A)[1] \n",
    "    a = Array{Float64,1}[]\n",
    "    u = Array{Float64,1}[]\n",
    "    for i in t_0:t\n",
    "        push!(a,zeros(i)+0.0)\n",
    "        push!(u,zeros(i)+0.0)\n",
    "    end\n",
    "\tb = zeros(t_0)\n",
    "\titers = 0\n",
    "\tdiff = 1.0\n",
    "\tb_old = b\n",
    "\twhile(diff >STOP_DIFF && iters< MAX_ITER )\n",
    "\t\tfor i in 1:new\n",
    "            a[i] = grad_descent(A[i],a_0,L[i],rho,vcat(b,zeros(i-1)),u[i],0.0001)\n",
    "        end\n",
    "        c = zeros(t)\n",
    "        for i in 1:new \n",
    "        \tc[1:(t_0 +i-1)] = c[1:(t_0 +i-1)]+ (u[i]+rho*(L[i]*a[i]))/(rho*new)\n",
    "        end\n",
    "        b = soft(c[1:t_0],2*lambda/rho)\n",
    "        #u update\n",
    "        for i in 1:new\n",
    "            u[i] = u[i]+ rho*(L[i]*a[i]-vcat(b,zeros(i-1)))\n",
    "        end\n",
    "        diff  = norm(b-b_old)\n",
    "        b_old = b\n",
    "        println(diff)\n",
    "    end\n",
    "    return(b)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using arXiv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefining constant STOP_DIFF\n"
     ]
    }
   ],
   "source": [
    "const MAX_ITER = 1000\n",
    "const STOP_DIFF = 0.0001;\n",
    "\n",
    "rho = 1\n",
    "lambda = 0.0001\n",
    "\n",
    "using LightGraphs\n",
    "using DataFrames\n",
    "\n",
    "\n",
    "data = readtable(\"training.csv\")\n",
    ";#change directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = maximum([maximum(data[:,4]),maximum(data[:,5])])\n",
    "g = BinaryTree(0)\n",
    "for i in 1:t\n",
    "\tadd_vertex!(g)\n",
    "end\n",
    "for i in 1:size(data,1)\n",
    "\tadd_edge!(g,data[i,4],data[i,5])\n",
    "end\n",
    "At = adjacency_matrix(g)\n",
    "\n",
    "\n",
    "A = Array{Int64,1}[]\n",
    "L =  SparseMatrixCSC{Int64,Int64}[]\n",
    "Adj =  SparseMatrixCSC{Int64,Int64}[]\n",
    "\n",
    "new = 25\n",
    "for i in reverse(1:new)\n",
    "    n = size(At)[1]\n",
    "    push!(A,full(At[n-i+1,1:n-i]))\n",
    "    push!(Adj, At[1:n-i,1:n-i])\n",
    "end\n",
    "\n",
    "for i in 1:size(Adj)[1]\n",
    "    push!(L,spdiagm(vec(sum(Adj[i],1))).-Adj[i])\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1432-element Array{Float64,1}:\n",
       " -0.0\n",
       "  0.0\n",
       " -0.0\n",
       " -0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       " -0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  â‹®  \n",
       " -0.0\n",
       "  0.0\n",
       " -0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       " -0.0\n",
       "  0.0\n",
       " -0.0\n",
       " -0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compb = ADMM2(A,L,rho,lambda,-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs(compb)  .>0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Base.LinAlg.SingularException(0)",
     "output_type": "error",
     "traceback": [
      "Base.LinAlg.SingularException(0)",
      "",
      " in umferror(::Int64) at ./sparse/umfpack.jl:22",
      " in solve!(::Array{Float64,1}, ::Base.SparseArrays.UMFPACK.UmfpackLU{Float64,Int64}, ::Array{Float64,1}, ::Int64) at ./sparse/umfpack.jl:260",
      " in \\(::Base.SparseArrays.UMFPACK.UmfpackLU{Float64,Int64}, ::Array{Float64,1}) at ./linalg/factorization.jl:40"
     ]
    }
   ],
   "source": [
    "lufact(L[1])\\(b-mean(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original, not enough variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "levels = 13     #number of levels in binary tree\n",
    "g = BinaryTree(levels)\n",
    "n = nv(g)\n",
    "b = (rand(n) .< 8 / n)*5. \n",
    "genb = copy(b)  # save for later\n",
    "g = randEdgeGen(g,10000)\n",
    "A = Array{Int64,1}[]\n",
    "L =  SparseMatrixCSC{Int64,Int64}[]\n",
    "numnewnodes = 100\n",
    "a_0 = -4\n",
    "# creates matrix A and L where A[i] is the connections for ith node and L[i] is the laplacian of the i-1st time step \n",
    "for i in 1:numnewnodes \n",
    "    push!(L, laplacian_matrix(g))\n",
    "    g = addPrefNode(g,b, a_0)\n",
    "    connects = zeros(2^levels-2+i)  #-1 for -1 1 coding\n",
    "    connects[neighbors(g,nv(g))] = 1\n",
    "    push!(A,connects)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0e-5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8191-element Array{Float64,1}:\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       "   â‹®\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b= ADMM2(A,L,rho,lambda,-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(test .>0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more variation needs work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const MAX_ITER = 1000\n",
    "const STOP_DIFF = 0.001;\n",
    "\n",
    "rho = 1\n",
    "lambda = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "levels = 10     #number of levels in binary tree\n",
    "g = BinaryTree(levels)\n",
    "n = nv(g)\n",
    "\n",
    "#dist = Gamma(2,2)\n",
    "#b = 50.*rand(dist,n)\n",
    "b = vec(readdlm(\"bvec.dat\"))\n",
    "\n",
    "genb = copy(b)  # save for later\n",
    "g = randEdgeGen(g,10000)\n",
    "A = Array{Int64,1}[]\n",
    "L =  SparseMatrixCSC{Int64,Int64}[]\n",
    "a_0 = 62\n",
    "numnewnodes = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creates matrix A and L where A[i] is the connections for ith node and L[i] is the laplacian of the i-1st time step \n",
    "for i in 1:numnewnodes \n",
    "    push!(L, laplacian_matrix(g))\n",
    "    g = addPrefNode(g,b,a_0 )\n",
    "    connects = zeros(2^levels-2+i)  #-1 for -1 1 coding\n",
    "    connects[neighbors(g,nv(g))] = 1\n",
    "    push!(A,connects)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
