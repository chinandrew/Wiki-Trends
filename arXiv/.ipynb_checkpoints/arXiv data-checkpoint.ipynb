{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition invLogit(Any) in module Main at In[1]:5 overwritten at In[21]:5.\n",
      "\u001b[1m\u001b[31mWARNING: replacing docs for 'invLogit :: Tuple{Any}' in module 'Main'.\u001b[0m\n",
      "WARNING: Method definition addNode2(Any, Any) in module Main at In[1]:13 overwritten at In[21]:13.\n",
      "\u001b[1m\u001b[31mWARNING: replacing docs for 'addNode2 :: Tuple{Any,Any}' in module 'Main'.\u001b[0m\n",
      "WARNING: Method definition addPrefNode(Any, Any) in module Main at In[1]:34 overwritten at In[21]:34.\n",
      "WARNING: Method definition addPrefNode(Any, Any, Any) in module Main at In[1]:34 overwritten at In[21]:34.\n",
      "\u001b[1m\u001b[31mWARNING: replacing docs for 'addPrefNode :: Union{Tuple{Any,Any,Any},Tuple{Any,Any}}' in module 'Main'.\u001b[0m\n",
      "WARNING: Method definition randEdgeGen(Any, Any) in module Main at In[1]:49 overwritten at In[21]:49.\n",
      "\u001b[1m\u001b[31mWARNING: replacing docs for 'randEdgeGen :: Tuple{Any,Any}' in module 'Main'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STABLE\n",
    "inverse logit function\n",
    "\"\"\"\n",
    "invLogit(x) = 1./(1.+e.^-x)   \n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "given graph and probability, adds a node which must have >0\n",
    "connections by flipping biased coin for each existing node\n",
    "\"\"\"\n",
    "function addNode2(graph, p)\n",
    "    add_vertex!(graph)\n",
    "    x = nv(graph)\n",
    "    degree = 0\n",
    "    while degree ==0\n",
    "        flips = rand(x-1)\n",
    "        for i = 1:x-1\n",
    "            if p[i]>flips[i]\n",
    "                add_edge!(graph,i,x)\n",
    "                degree +=1 \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return graph\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "given graph, b vector, and a_0, adds a new node as specifiec by the model\n",
    "\"\"\"\n",
    "function addPrefNode(g,b,a_0 = -7)\n",
    "    n = nv(g)\n",
    "    L::SparseMatrixCSC{Int64,Int64} = laplacian_matrix(g)\n",
    "    a::Array{Float64,1} = lufact(L) \\ (b - mean(b))\n",
    "    p::Array{Float64,1} = invLogit(a+a_0)\n",
    "    addNode2(g,p)\n",
    "    push!(b,0)\n",
    "    return g\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "given graph and number of new edges desired, randomly adds edges between existing nodes\n",
    "\"\"\"\n",
    "function randEdgeGen(graph, newedges)\n",
    "    for i in 1:newedges\n",
    "        z = newedges\n",
    "        x = collect(1:nv(graph))\n",
    "        edge1 = rand(x)\n",
    "        deleteat!(x, edge1)\n",
    "        edge2 = rand(x)\n",
    "        add_edge!(graph,edge1,edge2)\n",
    "    end\n",
    "    return graph\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition soft(Any, Any) in module Main at In[19]:5 overwritten at In[22]:5.\n",
      "\u001b[1m\u001b[31mWARNING: replacing docs for 'soft :: Tuple{Any,Any}' in module 'Main'.\u001b[0m\n",
      "WARNING: Method definition gradient2(Any, Any, Any, Any, Any, Any, Any) in module Main at In[19]:12 overwritten at In[22]:12.\n",
      "\u001b[1m\u001b[31mWARNING: replacing docs for 'gradient2 :: Tuple{Any,Any,Any,Any,Any,Any,Any}' in module 'Main'.\u001b[0m\n",
      "WARNING: Method definition gradient(Any, Any, Any, Any, Any, Any, Any) in module Main at In[19]:19 overwritten at In[22]:19.\n",
      "WARNING: Method definition hessian(Any, Any, Any, Any) in module Main at In[19]:30 overwritten at In[22]:30.\n",
      "\u001b[1m\u001b[31mWARNING: replacing docs for 'hessian :: Tuple{Any,Any,Any,Any}' in module 'Main'.\u001b[0m\n",
      "WARNING: Method definition newton(Any, Any, Any, Any, Any, Any) in module Main at In[19]:42 overwritten at In[22]:42.\n",
      "\u001b[1m\u001b[31mWARNING: replacing docs for 'newton :: Tuple{Any,Any,Any,Any,Any,Any}' in module 'Main'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STABLE\n",
    "soft threshold\n",
    "\"\"\"\n",
    "soft(c,lambda) = sign(c).*max(abs(c)-lambda/2,0)\n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "computes gradient\n",
    "\"\"\"\n",
    "function gradient2(a,a_0,u,L,rho,b,y)\n",
    "    convb::Array{Float64,2} =zeros(length(b),1)+b\n",
    "    grad::Array{Float64,2} = -1.*(y-invLogit(a+a_0))+L*u + rho*L*(L*a-convb)\n",
    "    return grad\n",
    "end;\n",
    "\n",
    "\n",
    "function gradient(a,a_0,u,L,rho,b,y)\n",
    "    grad = -1.*(y-invLogit(a+a_0))+L*u + rho*L*(L*a-b)\n",
    "    return grad\n",
    "end;\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "computes hessian\n",
    "\"\"\"\n",
    "function hessian(a,a_0,rho,L)\n",
    "    hess = Diagonal(vec((invLogit(a+a_0).*(1-invLogit(a+a_0)))))+rho*L^2\n",
    "    return hess\n",
    "end;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "STABLE\n",
    "newton raphson for a update\n",
    "\"\"\"\n",
    "function newton(y_i,a_0,L,rho,b,u)\n",
    "    a::Array{Float64,2} = zeros(length(y_i),1)\n",
    "    a_old = a\n",
    "    iters = 0\n",
    "    diff = 1.0\n",
    "    while(diff >STOP_DIFF && iters< MAX_ITER )\n",
    "        grad = gradient2(a_old,a_0,u,L,rho,b,y_i)\n",
    "        hess = hessian(a_old,a_0, rho,L)\n",
    "        a = a_old - inv(hess)*grad\n",
    "        diff = norm(a-a_old)\n",
    "        a_old = a\n",
    "        iters = iters+1\n",
    "        println(iters)\n",
    "    end\n",
    "    if(iters == MAX_ITER)\n",
    "        print(\"max iter reached\")\n",
    "    end\n",
    "    return a\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition ADMM(Any, Any, Any, Any, Any, Any) in module Main at In[3]:12 overwritten at In[23]:12.\n",
      "\u001b[1m\u001b[31mWARNING: replacing docs for 'ADMM :: Tuple{Any,Any,Any,Any,Any,Any}' in module 'Main'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2 Temp Vars UNSTABLE\n",
    "ADMM Function \n",
    "Parameters:\n",
    "A - Array of Array{Int64,2} of connections where each column is connections at time t\n",
    "L - Array of SparseMatrixCSC(Int64,Int64) where each index i is the laplacian at time t= i-1\n",
    "t - number of ending nodes\n",
    "t_0 - number of starting nodes\n",
    "lambda,rho -  Float64s for tuning and optimization\n",
    "\"\"\"\n",
    "function ADMM(A,L,t,t_0, rho, lambda)\n",
    "    new = t-t_0\n",
    "    a = zeros(t-1,new)\n",
    "    b = zeros(t_0,1) #::Array{Float64,2}\n",
    "    u = zeros(t-1,new)\n",
    "    iters = 0\n",
    "    diff = 1.0\n",
    "    b_old = b;\n",
    "\twhile(diff >STOP_DIFF && iters< MAX_ITER )\n",
    "        #a update\n",
    "        for i in 1:new    \n",
    "            a[1:(t_0 +i-1),i]= newton(A[i],a_0,L[i],rho,[b' zeros(i-1)']',u[1:(t_0 +i-1),i])\n",
    "        end\n",
    "        #b update\n",
    "        c = zeros(t-1,1)\n",
    "        for i in 1:new\n",
    "            c[1:(t_0 +i-1)] = c[1:(t_0 +i-1)]+ (u[1:(t_0 +i-1),i]+rho*(L[i]*a[1:(t_0 +i-1),i]))/(rho*new)\n",
    "        end\n",
    "        b = soft(c[1:t_0],2*lambda/rho)\n",
    "        #u update\n",
    "        for i in 1:new\n",
    "            u[1:(t_0 +i-1),i] = u[1:(t_0 +i-1),i]+ rho*(L[i]*a[1:(t_0 +i-1),i]-[b' zeros(i-1)']')\n",
    "        end\n",
    "        diff  = norm(b-b_old)\n",
    "        b_old = b\n",
    "        println(diff)\n",
    "\tend\n",
    "\treturn b\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1461"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LightGraphs\n",
    "using DataFrames\n",
    "\n",
    "\n",
    "data = readtable(\"training.csv\")\n",
    "\n",
    "t = maximum([maximum(data[:,4]),maximum(data[:,5])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test"
     ]
    }
   ],
   "source": [
    "for i in reverse(1:1)\n",
    "    print(\"test\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch(\"dimensions must match\")",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch(\"dimensions must match\")",
      "",
      " in promote_shape(::Tuple{Base.OneTo{Int64},Base.OneTo{Int64}}, ::Tuple{Base.OneTo{Int64}}) at ./operators.jl:406",
      " in promote_shape(::Array{Float64,2}, ::Array{Int64,1}) at ./operators.jl:397",
      " in _elementwise(::Base.#+, ::Type{Float64}, ::Array{Float64,2}, ::Array{Int64,1}) at ./arraymath.jl:57",
      " in +(::Array{Float64,2}, ::Array{Int64,1}) at ./arraymath.jl:49",
      " in macro expansion; at ./In[46]:20 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "g = BinaryTree(0)\n",
    "\n",
    "for i in 1:t\n",
    "\tadd_vertex!(g)\n",
    "end\n",
    "\n",
    "for i in 1:size(data,1)\n",
    "\tadd_edge!(g,data[i,4],data[i,5])\n",
    "end\n",
    "At = adjacency_matrix(g)\n",
    "\n",
    "\n",
    "A = Array{Int64,2}[]\n",
    "L =  SparseMatrixCSC{Int64,Int64}[]\n",
    "Adj =  SparseMatrixCSC{Int64,Int64}[]\n",
    "\n",
    "new = 1\n",
    "for i in reverse(1:new)\n",
    "    n = size(At)[1]\n",
    "    Ai = zeros(n-i,1)+full(At[n-i,1:n-i+1])\n",
    "    #Ai[n-i+1] = 0\n",
    "    push!(A,Ai[1:length(Ai)-1])\n",
    "    push!(Adj, At[1:n-i+1,1:n-i+1])\n",
    "end\n",
    "\n",
    "for adj in Adj\n",
    "    push!(L,spdiagm(vec(sum(Adj[1],1))).-Adj[1])\n",
    "end\n",
    "    \n",
    "    \n",
    "t_0 = t-new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 0-element Array{SparseMatrixCSC{Int64,Int64},1} at index [1]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 0-element Array{SparseMatrixCSC{Int64,Int64},1} at index [1]",
      "",
      " in getindex(::Array{SparseMatrixCSC{Int64,Int64},1}, ::Int64) at ./array.jl:386"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "const MAX_ITER = 1000\n",
    "const STOP_DIFF = 0.001;\n",
    "\n",
    "rho = 1\n",
    "lambda = 0.0005\n",
    "a_0 = -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 1460×1 Array{Float64,2} at index [1:1461]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 1460×1 Array{Float64,2} at index [1:1461]",
      "",
      " in throw_boundserror(::Array{Float64,2}, ::Tuple{UnitRange{Int64}}) at ./abstractarray.jl:355",
      " in checkbounds at ./abstractarray.jl:284 [inlined]",
      " in getindex at ./array.jl:392 [inlined]",
      " in ADMM(::Array{Array{Int64,2},1}, ::Array{SparseMatrixCSC{Int64,Int64},1}, ::Int64, ::Int64, ::Int64, ::Float64) at ./In[23]:29"
     ]
    }
   ],
   "source": [
    "ADMM(A,L,t,t_0,rho,lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new = t-t_0\n",
    "a = ones(t-1,new)\n",
    "b = ones(t_0,1).-0.5 #::Array{Float64,2}\n",
    "u = zeros(t-1,new)\n",
    "iters = 0\n",
    "diff = 1.0\n",
    "b_old = b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        for i in 1:new    \n",
    "                print(\"test\")\n",
    "\n",
    "            a[1:(t_0 +i-1),i]= newton(A[i],a_0,L[i],rho,[b' zeros(i-1)']',u[1:(t_0 +i-1),i])\n",
    "            print(\"test\")\n",
    "        end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 1460×1 Array{Float64,2} at index [1:1461]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 1460×1 Array{Float64,2} at index [1:1461]",
      "",
      " in throw_boundserror(::Array{Float64,2}, ::Tuple{UnitRange{Int64}}) at ./abstractarray.jl:355",
      " in checkbounds at ./abstractarray.jl:284 [inlined]",
      " in getindex(::Array{Float64,2}, ::UnitRange{Int64}) at ./array.jl:392",
      " in macro expansion; at ./In[85]:4 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "        #b update\n",
    "        c = zeros(t-1,1)\n",
    "        for i in 1:new\n",
    "            c[1:(t_0 +i-1)] = c[1:(t_0 +i-1)]+ (u[1:(t_0 +i-1),i]+rho*(L[i]*a[1:(t_0 +i-1),i]))/(rho*new)\n",
    "        end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        b = soft(c[1:t_0],2*lambda/rho)\n",
    "        #u update\n",
    "        for i in 1:new\n",
    "            u[1:(t_0 +i-1),i] = u[1:(t_0 +i-1),i]+ rho*(L[i]*a[1:(t_0 +i-1),i]-[b' zeros(i-1)']')\n",
    "        end\n",
    "        diff  = norm(b-b_old)\n",
    "        b_old = b\n",
    "        println(diff)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
